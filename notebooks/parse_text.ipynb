{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a39089-b307-4582-8cb3-f200acf8ff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'papers_drug_discovery/Accelerating materials discovery using artificial intelligence,'$'\\n''high performance computing and robotics.pdf'\n"
     ]
    }
   ],
   "source": [
    "!ls papers_drug_discovery/'Accelerating materials discovery using artificial intelligence,'$'\\n''high performance computing and robotics.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad3fdef5-368f-4aa4-9f9f-dc1ba67fd8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10.1080@17460441.2020.1758664.pdf\n",
      " 10.4155@fmc-2019-0307.pdf\n",
      "'Accelerating materials discovery using artificial intelligence,'$'\\n''high performance computing and robotics.pdf'\n",
      "'Application of computational methods for anticancer'$'\\n''drug discovery, design, and optimization.pdf'\n",
      " ballester2009.pdf\n",
      "'Computational approaches streamlining'$'\\n''drug discovery.pdf'\n",
      " drwal2013.pdf\n",
      "'From machine learning to deep'$'\\n''learning: progress in machine'$'\\n''intelligence for rational drug'$'\\n''discovery.pdf'\n",
      " lauro2012.pdf\n",
      " lyne2002.pdf\n",
      " malik2017.pdf\n",
      " molecules-25-01375.pdf\n",
      " walters1998.pdf\n"
     ]
    }
   ],
   "source": [
    "!ls papers_drug_discovery/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f094dc9-5936-4da5-9d7d-6adc7872208d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a18cddde-51fc-4e32-922d-ac13f12b3a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting numpy>=1.20.3 (from pandas)\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 tzdata-2024.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b544e1-be5f-450c-9a9c-052d395b9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "pdf = pymupdf.open('papers_drug_discovery/Accelerating materials discovery using artificial intelligence,\\nhigh performance computing and robotics.pdf')\n",
    "page = pdf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb111b91-cd94-4aba-9d59-31c65ec16645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabtest(x_line, x_columns):\n",
    "    column = 0\n",
    "    column_dist = x_line - x_columns[0]\n",
    "    if column_dist < 0:\n",
    "        column_dist = 10000\n",
    "    \n",
    "    for i in range(1, len(x_columns)):\n",
    "        print(x_line - x_columns[i])\n",
    "        if (x_line - x_columns[i]) < column_dist and (x_line - x_columns[i]) >= 0:\n",
    "            column = i\n",
    "\n",
    "    if (x_line - x_columns[column]) > 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "107760e5-86e0-4dd3-a54b-f2a0c40cd42a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read page text as a dictionary, suppressing extra spaces in CJK fonts\n",
    "\n",
    "blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "doc_order = []\n",
    "for b in blocks:  # iterate through the text blocks\n",
    "    \n",
    "    if \"lines\" in b:\n",
    "        \n",
    "        y = 0\n",
    "        text = \"\"\n",
    "        font_size = 1\n",
    "        block_lines = []\n",
    "        for l in b[\"lines\"]:  # iterate through the text lines\n",
    "            for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                if round(s['size']) > 8:\n",
    "                    if round(s[\"origin\"][1]) > y:\n",
    "                        if y > 0:\n",
    "                            block_lines.append({\n",
    "                                \"type\": \"line\",\n",
    "                                \"font_size\": font_size, \n",
    "                                \"x\": x, \n",
    "                                \"y\": y, \n",
    "                                \"text\": text,\n",
    "                                \"tab\": False\n",
    "                            })\n",
    "                        y = round(s[\"origin\"][1])\n",
    "                        x = round(s[\"origin\"][0])\n",
    "                        text = s['text']\n",
    "                        font_size = round(s['size'])\n",
    "                    else:\n",
    "                        text = text + \" \" + s['text']\n",
    "\n",
    "        block_lines.append({\n",
    "                    \"type\": \"line\",\n",
    "                    \"font_size\": font_size, \n",
    "                    \"x\": x, \n",
    "                    \"y\": y, \n",
    "                    \"text\": text,\n",
    "                    \"tab\": False\n",
    "                })\n",
    "                        \n",
    "\n",
    "        doc_order.append(block_lines)\n",
    "                        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e4ea3-5a21-4b2e-a9cd-0d229641eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a879e937-64d6-47b3-b800-fafe0fcac743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 is tabbed with respect to 36\n",
      "{'type': 'line', 'font_size': 9, 'x': 45, 'y': 452, 'text': 'Historically, science has seen a number of major paradigm', 'tab': True}\n",
      "45 is tabbed with respect to 36\n",
      "{'type': 'line', 'font_size': 9, 'x': 45, 'y': 654, 'text': 'A typical materials discovery effort can be decomposed into a', 'tab': True}\n",
      "311 is tabbed with respect to 302\n",
      "{'type': 'line', 'font_size': 9, 'x': 311, 'y': 627, 'text': 'In this perspective, we describe technologies we have been', 'tab': True}\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "from statistics import mode\n",
    "\n",
    "for b in doc_order:\n",
    "    xs = [l[\"x\"] for l in b]\n",
    "    if len(xs) > 2:\n",
    "        for l in b:\n",
    "            if l[\"x\"] > mode(xs):\n",
    "                print(l[\"x\"], \"is tabbed with respect to\", mode(xs))\n",
    "                l[\"tab\"] = True\n",
    "                print(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221bac2e-01b4-4bbf-91e0-925c215f5260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b797b4-cd24-423c-928b-739e6dad7953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bacb3b5-ba98-4526-bca6-eec18e0c8be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a1d2c20-409d-4786-8bd8-0c8cf920cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "255f44f1-de9e-48fa-ab57-e54608d3949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = pandas.Series(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cbbd76ec-7cb6-4b62-a3ec-bbf7e17f1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = my_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb455f9-9799-49e4-a56e-ee7b04ac1f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "236d17a1-1781-447e-bab0-93cb0285cb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{36: 36, 302: 32, 48: 5, 45: 2, 311: 1}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "318ac3c2-4eb6-4337-bfa5-f638ae895070",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dict(counts).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9e696443-fb6e-4bde-8a07-4ec495d4e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([36, 302, 48, 45, 311])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d031d-9192-42eb-9159-9f985d50b4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
